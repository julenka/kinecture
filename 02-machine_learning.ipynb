{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classifiers with Base Features\n",
    "The first thing I always try is a support vector machine. From the data exploration we saw the boundary was nonlinear, so a nonlinear kernel might do better here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load stuff we will need\n",
    "import pandas as pd\n",
    "import kinecture\n",
    "import math\n",
    "\n",
    "# When we make changes to modules, automatically reload the modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and generate features\n",
    "1. Load data, clean, make features.\n",
    "2. Convert data to a form sklearn understands: X (observations), y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train instances: 8906\n",
      "test09 instances: 1108\n",
      "test10 instances: 1068\n",
      "test11 instances: 1149\n"
     ]
    }
   ],
   "source": [
    "# load data, generate features\n",
    "xls = pd.ExcelFile('data/allData-filtered.xlsx')\n",
    "train_dataframe = xls.parse('filtered-noFormulas')\n",
    "test09_dataframe = xls.parse('09test')\n",
    "test10_dataframe = xls.parse('10test')\n",
    "test11_dataframe = xls.parse('11test')\n",
    "\n",
    "print(\"train instances:\", len(train_dataframe))\n",
    "print(\"test09 instances:\", len(test09_dataframe))\n",
    "print(\"test10 instances:\", len(test10_dataframe))\n",
    "print(\"test11 instances:\", len(test11_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate features (determined from data_exploration)\n",
    "train_features = kinecture.gen_features(train_dataframe)\n",
    "test09_features = kinecture.gen_features(test09_dataframe)\n",
    "test10_features = kinecture.gen_features(test10_dataframe)\n",
    "test11_features = kinecture.gen_features(test11_dataframe)\n",
    "\n",
    "test09_features['Truth'] = kinecture.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test09_features['Truth'])\n",
    "test10_features['Truth'] = kinecture.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test10_features['Truth'])\n",
    "test11_features['Truth'] = kinecture.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test11_features['Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = kinecture.clean_data(train_features)\n",
    "test09_features = kinecture.clean_data(test09_features)\n",
    "test10_features = kinecture.clean_data(test10_features)\n",
    "test11_features = kinecture.clean_data(test11_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert data into a form sklearn likes\n",
    "train_sklearn = kinecture.convert_features_for_sklearn(train_features)\n",
    "test09_sklearn = kinecture.convert_features_for_sklearn(test09_features)\n",
    "test10_sklearn = kinecture.convert_features_for_sklearn(test10_features)\n",
    "test11_sklearn = kinecture.convert_features_for_sklearn(test11_features)\n",
    "\n",
    "testall_sklearn = test09_sklearn.append(test10_sklearn).append(test11_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Linear Classifier Using Test Sets\n",
    "First I start by building a classifier using a simple linear decision boundary. \n",
    "\n",
    "I adjusted the importance of each class to be inversely proportional to the class frequency (`class_weight: auto`). This ensures that recall for all classes will be roughly equal, even though there are many more TA and SI instances than S instances. I could also set just the S class to be more important by setting `class_weights={0:3}`, this will make class 0 (S) 3 times more important than SI or TA.\n",
    "\n",
    "Best results for all test sessions are as follows (using C=1):\n",
    "\n",
    "\n",
    "             S   SI   TA\n",
    "        S  669  232  147\n",
    "       SI  300  624  195\n",
    "       TA  139  397  622\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          S       0.60      0.64      0.62      1048\n",
    "         SI       0.50      0.56      0.53      1119\n",
    "         TA       0.65      0.54      0.59      1158\n",
    "      total       0.58      0.58      0.58      3325\n",
    "\n",
    "We see an average recall of 58% which is not good, suggesting better features are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for LinearSVC\n",
      "{'C': 0.75}\n",
      "\n",
      "results for train\n",
      "             S   SI   TA\n",
      "        S 3217  810  200\n",
      "       SI  948 1919  366\n",
      "       TA  369  473  604\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.71      0.76      0.73      4227\n",
      "         SI       0.60      0.59      0.60      3233\n",
      "         TA       0.52      0.42      0.46      1446\n",
      "\n",
      "avg / total       0.64      0.64      0.64      8906\n",
      "\n",
      "results for testall\n",
      "             S   SI   TA\n",
      "        S  650  427   81\n",
      "       SI  199  735  185\n",
      "       TA  171  385  492\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.64      0.56      0.60      1158\n",
      "         SI       0.48      0.66      0.55      1119\n",
      "         TA       0.65      0.47      0.54      1048\n",
      "\n",
      "avg / total       0.59      0.56      0.57      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.1, 0.75, 1, 5, 10]}]\n",
    "\n",
    "# build LinearSVC classifier using training data\n",
    "classifier = GridSearchCV(svm.LinearSVC(class_weight='auto'), tuned_parameters)\n",
    "classifier.fit(train_sklearn.X, train_sklearn.y)\n",
    "\n",
    "print(\"Best params for LinearSVC\")\n",
    "print(classifier.best_params_)\n",
    "print()\n",
    "\n",
    "train_predictions = classifier.predict(train_sklearn.X)\n",
    "kinecture.report_accuracy(train_predictions, train_sklearn.y, header=\"results for train\")\n",
    "\n",
    "testall_predictions = classifier.predict(testall_sklearn.X)\n",
    "kinecture.report_accuracy(testall_predictions, testall_sklearn.y, header=\"results for testall\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classifier with nonlinear kernels\n",
    "Since we observed that, at least for pairs of variables, features were not linearly seperable, a more complex decision boundary may perform better.\n",
    "\n",
    "Results for the test were as follows:\n",
    "\n",
    "             S   SI   TA\n",
    "        S  545  350  153\n",
    "       SI  219  711  189\n",
    "       TA  162  380  616\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          S       0.59      0.52      0.55      1048\n",
    "         SI       0.49      0.64      0.56      1119\n",
    "         TA       0.64      0.53      0.58      1158\n",
    "\n",
    "      total       0.58      0.56      0.56      3325\n",
    "      \n",
    "With the nonlinear classifier we see slightly lower recall, suggesting some overfitting to the training data.\n",
    "\n",
    "Overall, my suggestion would be to focus on improving the features, since increasing the model complexity does not seem to be helping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for SVC with rbf kernel\n",
      "{'gamma': 10, 'C': 0.1}\n",
      "\n",
      "train\n",
      "             S   SI   TA\n",
      "        S  681  307  458\n",
      "       SI  366 2944  917\n",
      "       TA  450  844 1939\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.45      0.47      0.46      1446\n",
      "         SI       0.72      0.70      0.71      4227\n",
      "         TA       0.59      0.60      0.59      3233\n",
      "\n",
      "avg / total       0.63      0.62      0.63      8906\n",
      "\n",
      "test09\n",
      "             S   SI   TA\n",
      "        S  150   91   29\n",
      "       SI   48  257  194\n",
      "       TA   61  130  148\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.58      0.56      0.57       270\n",
      "         SI       0.54      0.52      0.53       499\n",
      "         TA       0.40      0.44      0.42       339\n",
      "\n",
      "avg / total       0.51      0.50      0.50      1108\n",
      "\n",
      "test10\n",
      "             S   SI   TA\n",
      "        S  215    2   16\n",
      "       SI   37  232   93\n",
      "       TA  104   54  315\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.60      0.92      0.73       233\n",
      "         SI       0.81      0.64      0.71       362\n",
      "         TA       0.74      0.67      0.70       473\n",
      "\n",
      "avg / total       0.73      0.71      0.71      1068\n",
      "\n",
      "test11\n",
      "             S   SI   TA\n",
      "        S  161   66  318\n",
      "       SI   76  130   91\n",
      "       TA   39    7  261\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.58      0.30      0.39       545\n",
      "         SI       0.64      0.44      0.52       297\n",
      "         TA       0.39      0.85      0.53       307\n",
      "\n",
      "avg / total       0.55      0.48      0.46      1149\n",
      "\n",
      "testall\n",
      "             S   SI   TA\n",
      "        S  526  159  363\n",
      "       SI  161  619  378\n",
      "       TA  204  191  724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.59      0.50      0.54      1048\n",
      "         SI       0.64      0.53      0.58      1158\n",
      "         TA       0.49      0.65      0.56      1119\n",
      "\n",
      "avg / total       0.57      0.56      0.56      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.1, 0.5, 1], 'gamma': [10, 20, 30]}]\n",
    "\n",
    "classifier = GridSearchCV(svm.SVC(class_weight='auto'), tuned_parameters)\n",
    "classifier.fit(train_sklearn.X, train_sklearn.y)\n",
    "\n",
    "print(\"Best params for SVC with rbf kernel\")\n",
    "print(classifier.best_params_)\n",
    "print()\n",
    "\n",
    "train_predictions = classifier.predict(train_sklearn.X)\n",
    "kinecture.report_accuracy(train_predictions, train_sklearn.y, header=\"train\")\n",
    "\n",
    "testall_predictions = classifier.predict(testall_sklearn.X)\n",
    "kinecture.report_accuracy(testall_predictions, testall_sklearn.y, header=\"testall\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Looks like the features we have don't separate the data very well.  The next steps would be to try improving the features, see if adding more data will help, and seeing if we can get more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
