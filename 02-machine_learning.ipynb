{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classifiers with Base Features\n",
    "The first thing I always try is a support vector machine. From the data exploration we saw the boundary was nonlinear, so a nonlinear kernel might do better here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load stuff we will need\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from kinecture import ml_helper\n",
    "\n",
    "# When we make changes to modules, automatically reload the modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and generate features\n",
    "1. Load data, clean, make features.\n",
    "2. Convert data to a form sklearn understands: X (observations), y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train instances: 8906\n",
      "test09 instances: 1108\n",
      "test10 instances: 1068\n",
      "test11 instances: 1149\n"
     ]
    }
   ],
   "source": [
    "# load data, generate features\n",
    "xls = pd.ExcelFile('data/allData-filtered.xlsx')\n",
    "train_dataframe = xls.parse('filtered-noFormulas')\n",
    "test09_dataframe = xls.parse('09test')\n",
    "test10_dataframe = xls.parse('10test')\n",
    "test11_dataframe = xls.parse('11test')\n",
    "\n",
    "print(\"train instances:\", len(train_dataframe))\n",
    "print(\"test09 instances:\", len(test09_dataframe))\n",
    "print(\"test10 instances:\", len(test10_dataframe))\n",
    "print(\"test11 instances:\", len(test11_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate features (determined from data_exploration)\n",
    "train_features = ml_helper.gen_features(train_dataframe)\n",
    "test09_features = ml_helper.gen_features(test09_dataframe)\n",
    "test10_features = ml_helper.gen_features(test10_dataframe)\n",
    "test11_features = ml_helper.gen_features(test11_dataframe)\n",
    "\n",
    "test09_features['Truth'] = ml_helper.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test09_features['Truth'])\n",
    "test10_features['Truth'] = ml_helper.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test10_features['Truth'])\n",
    "test11_features['Truth'] = ml_helper.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test11_features['Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = ml_helper.clean_data(train_features)\n",
    "test09_features = ml_helper.clean_data(test09_features)\n",
    "test10_features = ml_helper.clean_data(test10_features)\n",
    "test11_features = ml_helper.clean_data(test11_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert data into a form sklearn likes\n",
    "train_sklearn = ml_helper.convert_features_for_sklearn(train_features)\n",
    "test09_sklearn = ml_helper.convert_features_for_sklearn(test09_features)\n",
    "test10_sklearn = ml_helper.convert_features_for_sklearn(test10_features)\n",
    "test11_sklearn = ml_helper.convert_features_for_sklearn(test11_features)\n",
    "\n",
    "testall_sklearn = test09_sklearn.append(test10_sklearn).append(test11_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Linear Classifier Using Test Sets\n",
    "First I start by building a classifier using a simple linear decision boundary. \n",
    "\n",
    "I adjusted the importance of each class to be inversely proportional to the class frequency (`class_weight: auto`). This ensures that recall for all classes will be roughly equal, even though there are many more TA and SI instances than S instances. I could also set just the S class to be more important by setting `class_weights={0:3}`, this will make class 0 (S) 3 times more important than SI or TA.\n",
    "\n",
    "Best results for all test sessions are as follows (using C=1):\n",
    "\n",
    "\n",
    "             S   SI   TA\n",
    "        S  669  232  147\n",
    "       SI  300  624  195\n",
    "       TA  139  397  622\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          S       0.60      0.64      0.62      1048\n",
    "         SI       0.50      0.56      0.53      1119\n",
    "         TA       0.65      0.54      0.59      1158\n",
    "      total       0.58      0.58      0.58      3325\n",
    "\n",
    "We see an average recall of 58% which is not good, suggesting better features are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for LinearSVC\n",
      "{'C': 0.75}\n",
      "\n",
      "results for train\n",
      "             S   SI   TA\n",
      "        S 3226  805  196\n",
      "       SI  950 1918  365\n",
      "       TA  376  466  604\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.71      0.76      0.73      4227\n",
      "         SI       0.60      0.59      0.60      3233\n",
      "         TA       0.52      0.42      0.46      1446\n",
      "\n",
      "avg / total       0.64      0.65      0.64      8906\n",
      "\n",
      "results for testall\n",
      "             S   SI   TA\n",
      "        S  648  375  135\n",
      "       SI  200  619  300\n",
      "       TA  167  232  649\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.64      0.56      0.60      1158\n",
      "         SI       0.50      0.55      0.53      1119\n",
      "         TA       0.60      0.62      0.61      1048\n",
      "\n",
      "avg / total       0.58      0.58      0.58      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.1, 0.75, 1, 5, 10]}]\n",
    "\n",
    "# build LinearSVC classifier using training data\n",
    "classifier = GridSearchCV(svm.LinearSVC(class_weight='auto'), tuned_parameters)\n",
    "classifier.fit(train_sklearn.X, train_sklearn.y)\n",
    "\n",
    "print(\"Best params for LinearSVC\")\n",
    "print(classifier.best_params_)\n",
    "print()\n",
    "\n",
    "train_predictions = classifier.predict(train_sklearn.X)\n",
    "ml_helper.report_accuracy(train_predictions, train_sklearn.y, header=\"results for train\")\n",
    "\n",
    "testall_predictions = classifier.predict(testall_sklearn.X)\n",
    "ml_helper.report_accuracy(testall_predictions, testall_sklearn.y, header=\"results for testall\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classifier with nonlinear kernels\n",
    "Since we observed that, at least for pairs of variables, features were not linearly seperable, a more complex decision boundary may perform better.\n",
    "\n",
    "Results for the test were as follows:\n",
    "\n",
    "             S   SI   TA\n",
    "        S  545  350  153\n",
    "       SI  219  711  189\n",
    "       TA  162  380  616\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          S       0.59      0.52      0.55      1048\n",
    "         SI       0.49      0.64      0.56      1119\n",
    "         TA       0.64      0.53      0.58      1158\n",
    "\n",
    "      total       0.58      0.56      0.56      3325\n",
    "      \n",
    "With the nonlinear classifier we see slightly lower recall, suggesting some overfitting to the training data.\n",
    "\n",
    "Overall, my suggestion would be to focus on improving the features, since increasing the model complexity does not seem to be helping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for SVC with rbf kernel\n",
      "{'C': 0.1, 'gamma': 10}\n",
      "\n",
      "train\n",
      "             S   SI   TA\n",
      "        S 3058  884  285\n",
      "       SI  893 1925  415\n",
      "       TA  348  473  625\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.71      0.72      0.72      4227\n",
      "         SI       0.59      0.60      0.59      3233\n",
      "         TA       0.47      0.43      0.45      1446\n",
      "\n",
      "avg / total       0.63      0.63      0.63      8906\n",
      "\n",
      "testall\n",
      "             S   SI   TA\n",
      "        S  617  411  130\n",
      "       SI  188  723  208\n",
      "       TA  164  354  530\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.64      0.53      0.58      1158\n",
      "         SI       0.49      0.65      0.55      1119\n",
      "         TA       0.61      0.51      0.55      1048\n",
      "\n",
      "avg / total       0.58      0.56      0.56      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.1, 0.5, 1], 'gamma': [10, 20, 30]}]\n",
    "\n",
    "classifier = GridSearchCV(svm.SVC(class_weight='auto'), tuned_parameters)\n",
    "classifier.fit(train_sklearn.X, train_sklearn.y)\n",
    "\n",
    "print(\"Best params for SVC with rbf kernel\")\n",
    "print(classifier.best_params_)\n",
    "print()\n",
    "\n",
    "train_predictions = classifier.predict(train_sklearn.X)\n",
    "ml_helper.report_accuracy(train_predictions, train_sklearn.y, header=\"train\")\n",
    "\n",
    "testall_predictions = classifier.predict(testall_sklearn.X)\n",
    "ml_helper.report_accuracy(testall_predictions, testall_sklearn.y, header=\"testall\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Looks like the features we have don't separate the data very well.  The next steps would be to try improving the features, see if adding more data will help, and seeing if we can get more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
