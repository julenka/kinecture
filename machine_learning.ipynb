{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load stuff we will need\n",
    "import pandas as pd\n",
    "import kinecture\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# When we make changes to modules, automatically reload the modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and generate features\n",
    "1. Load data, clean, make features.\n",
    "2. Convert data to a form sklearn understands: X (observations), y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train instances: 8906\n",
      "test09 instances: 1108\n",
      "test10 instances: 1068\n",
      "test11 instances: 1149\n"
     ]
    }
   ],
   "source": [
    "# load data, generate features\n",
    "xls = pd.ExcelFile('data/allData-filtered.xlsx')\n",
    "train_dataframe = xls.parse('filtered-noFormulas')\n",
    "test09_dataframe = xls.parse('09test')\n",
    "test10_dataframe = xls.parse('10test')\n",
    "test11_dataframe = xls.parse('11test')\n",
    "\n",
    "print(\"train instances:\", len(train_dataframe))\n",
    "print(\"test09 instances:\", len(test09_dataframe))\n",
    "print(\"test10 instances:\", len(test10_dataframe))\n",
    "print(\"test11 instances:\", len(test11_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate features (determined from data_exploration)\n",
    "train_features = kinecture.gen_features(train_dataframe)\n",
    "test09_features = kinecture.gen_features(test09_dataframe)\n",
    "test10_features = kinecture.gen_features(test10_dataframe)\n",
    "test11_features = kinecture.gen_features(test11_dataframe)\n",
    "\n",
    "test09_features['Truth'] = kinecture.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test09_features['Truth'])\n",
    "test10_features['Truth'] = kinecture.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test10_features['Truth'])\n",
    "test11_features['Truth'] = kinecture.remap_labels({\"SI-FIX\": \"SI\"}, \n",
    "                                                 test11_features['Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'angleLeft', 'angleRight', 'confidenceLeft',\n",
      "       'confidenceRight', 'loudnessLeft', 'loudnessRight', 'silenceLeft',\n",
      "       'silenceRight', 'speakerX', 'speakerY', 'confLangle', 'confRangle',\n",
      "       'pLeft', 'pRight', 'qLeft', 'qRight', 'loudnessAve', 'loudnessDiff',\n",
      "       'pLeftZ', 'pRightZ', 'qLeftZ', 'qRightZ', 'logLoud', 'logLoudDiff',\n",
      "       'logLoudZ', 'logLoudDiffZ', 'logLoudnessLeft', 'logLoudnessRight',\n",
      "       'averageLogLoudness', 'silenceLeftAndRight', 'silenceLeftOrRight',\n",
      "       'speakerXYNorm', 'speakerXIs0', 'sinAngleLeft', 'sinAngleRight',\n",
      "       'Truth'],\n",
      "      dtype='object')\n",
      "37 features\n"
     ]
    }
   ],
   "source": [
    "print(train_features.columns)\n",
    "print(\"{} features\".format(len(train_features.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert data into a form sklearn likes\n",
    "train_sklearn = kinecture.convert_features_for_sklearn(train_features)\n",
    "test09_sklearn = kinecture.convert_features_for_sklearn(test09_features)\n",
    "test10_sklearn = kinecture.convert_features_for_sklearn(test10_features)\n",
    "test11_sklearn = kinecture.convert_features_for_sklearn(test11_features)\n",
    "\n",
    "testall_sklearn = test09_sklearn.append(test10_sklearn).append(test11_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a linear classifier\n",
    "First I start by building a classifier using a simple linear decision boundary. \n",
    "\n",
    "I adjusted the importance of each class to be inversely proportional to the class frequency (`class_weight: auto`). This ensures that recall for all classes will be roughly equal, even though there are many more TA and SI instances than S instances. I could also set just the S class to be more important by setting `class_weights={0:3}`, this will make class 0 (S) 3 times more important than SI or TA.\n",
    "\n",
    "Results for all test sessions are as follows:\n",
    "\n",
    "\n",
    "             S   SI   TA\n",
    "        S  669  232  147\n",
    "       SI  300  624  195\n",
    "       TA  139  397  622\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          S       0.60      0.64      0.62      1048\n",
    "         SI       0.50      0.56      0.53      1119\n",
    "         TA       0.65      0.54      0.59      1158\n",
    "      total       0.58      0.58      0.58      3325\n",
    "\n",
    "We see an average recall of 58% which is not good, suggesting better features are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for LinearSVC\n",
      "{'C': 1}\n",
      "\n",
      "results for train\n",
      "             S   SI   TA\n",
      "        S  627  457  362\n",
      "       SI  392 1909  932\n",
      "       TA  206  844 3177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.51      0.43      0.47      1446\n",
      "         SI       0.59      0.59      0.59      3233\n",
      "         TA       0.71      0.75      0.73      4227\n",
      "\n",
      "avg / total       0.64      0.64      0.64      8906\n",
      "\n",
      "results for test09\n",
      "             S   SI   TA\n",
      "        S  152   29   89\n",
      "       SI   61  146  132\n",
      "       TA   48  195  256\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.58      0.56      0.57       270\n",
      "         SI       0.39      0.43      0.41       339\n",
      "         TA       0.54      0.51      0.52       499\n",
      "\n",
      "avg / total       0.50      0.50      0.50      1108\n",
      "\n",
      "results for test10\n",
      "             S   SI   TA\n",
      "        S  218   12    3\n",
      "       SI  118  299   56\n",
      "       TA   22  103  237\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.61      0.94      0.74       233\n",
      "         SI       0.72      0.63      0.67       473\n",
      "         TA       0.80      0.65      0.72       362\n",
      "\n",
      "avg / total       0.72      0.71      0.70      1068\n",
      "\n",
      "results for test11\n",
      "             S   SI   TA\n",
      "        S  299  191   55\n",
      "       SI  121  179    7\n",
      "       TA   69   99  129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.61      0.55      0.58       545\n",
      "         SI       0.38      0.58      0.46       307\n",
      "         TA       0.68      0.43      0.53       297\n",
      "\n",
      "avg / total       0.57      0.53      0.53      1149\n",
      "\n",
      "results for testall\n",
      "             S   SI   TA\n",
      "        S  669  232  147\n",
      "       SI  300  624  195\n",
      "       TA  139  397  622\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.60      0.64      0.62      1048\n",
      "         SI       0.50      0.56      0.53      1119\n",
      "         TA       0.65      0.54      0.59      1158\n",
      "\n",
      "avg / total       0.58      0.58      0.58      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.1, 1, 10]}]\n",
    "\n",
    "# build LinearSVC classifier using training data\n",
    "classifier = GridSearchCV(svm.LinearSVC(class_weight='auto'), tuned_parameters)\n",
    "classifier.fit(train_sklearn.X, train_sklearn.y)\n",
    "\n",
    "print(\"Best params for LinearSVC\")\n",
    "print(classifier.best_params_)\n",
    "print()\n",
    "\n",
    "train_predictions = classifier.predict(train_sklearn.X)\n",
    "kinecture.report_accuracy(train_predictions, train_sklearn.y, header=\"results for train\")\n",
    "\n",
    "test09_predictions = classifier.predict(test09_sklearn.X)\n",
    "kinecture.report_accuracy(test09_predictions, test09_sklearn.y, header=\"results for test09\")\n",
    "\n",
    "test10_predictions = classifier.predict(test10_sklearn.X)\n",
    "kinecture.report_accuracy(test10_predictions, test10_sklearn.y, header=\"results for test10\")\n",
    "\n",
    "test11_predictions = classifier.predict(test11_sklearn.X)\n",
    "kinecture.report_accuracy(test11_predictions, test11_sklearn.y, header=\"results for test11\")\n",
    "\n",
    "testall_predictions = classifier.predict(testall_sklearn.X)\n",
    "kinecture.report_accuracy(testall_predictions, testall_sklearn.y, header=\"results for testall\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classifier with nonlinear kernels\n",
    "Since we observed that, at least for pairs of variables, features were not linearly seperable, a more complex decision boundary may perform better.\n",
    "\n",
    "Results for the test were as follows:\n",
    "\n",
    "             S   SI   TA\n",
    "        S  545  350  153\n",
    "       SI  219  711  189\n",
    "       TA  162  380  616\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          S       0.59      0.52      0.55      1048\n",
    "         SI       0.49      0.64      0.56      1119\n",
    "         TA       0.64      0.53      0.58      1158\n",
    "\n",
    "      total       0.58      0.56      0.56      3325\n",
    "      \n",
    "With the nonlinear classifier we see slightly lower recall, suggesting some overfitting to the training data.\n",
    "\n",
    "Overall, my suggestion would be to focus on improving the features, since increasing the model complexity does not seem to be helping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for LinearSVC\n",
      "{'C': 0.1, 'gamma': 10}\n",
      "\n",
      "train\n",
      "             S   SI   TA\n",
      "        S  676  460  310\n",
      "       SI  450 1936  847\n",
      "       TA  360  913 2954\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.45      0.47      0.46      1446\n",
      "         SI       0.59      0.60      0.59      3233\n",
      "         TA       0.72      0.70      0.71      4227\n",
      "\n",
      "avg / total       0.63      0.62      0.63      8906\n",
      "\n",
      "test09\n",
      "             S   SI   TA\n",
      "        S  153   31   86\n",
      "       SI   61  148  130\n",
      "       TA   48  196  255\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.58      0.57      0.58       270\n",
      "         SI       0.39      0.44      0.41       339\n",
      "         TA       0.54      0.51      0.53       499\n",
      "\n",
      "avg / total       0.51      0.50      0.50      1108\n",
      "\n",
      "test10\n",
      "             S   SI   TA\n",
      "        S  219   12    2\n",
      "       SI  118  303   52\n",
      "       TA   37   93  232\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.59      0.94      0.72       233\n",
      "         SI       0.74      0.64      0.69       473\n",
      "         TA       0.81      0.64      0.72       362\n",
      "\n",
      "avg / total       0.73      0.71      0.70      1068\n",
      "\n",
      "test11\n",
      "             S   SI   TA\n",
      "        S  173  307   65\n",
      "       SI   40  260    7\n",
      "       TA   77   91  129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.60      0.32      0.41       545\n",
      "         SI       0.40      0.85      0.54       307\n",
      "         TA       0.64      0.43      0.52       297\n",
      "\n",
      "avg / total       0.55      0.49      0.47      1149\n",
      "\n",
      "testall\n",
      "             S   SI   TA\n",
      "        S  545  350  153\n",
      "       SI  219  711  189\n",
      "       TA  162  380  616\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          S       0.59      0.52      0.55      1048\n",
      "         SI       0.49      0.64      0.56      1119\n",
      "         TA       0.64      0.53      0.58      1158\n",
      "\n",
      "avg / total       0.58      0.56      0.56      3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# use grid search to find best hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.1, 0.5, 1], 'gamma': [10, 20, 30]}]\n",
    "\n",
    "classifier = GridSearchCV(svm.SVC(class_weight='auto'), tuned_parameters)\n",
    "classifier.fit(train_sklearn.X, train_sklearn.y)\n",
    "\n",
    "print(\"Best params for SVC with rbf kernel\")\n",
    "print(classifier.best_params_)\n",
    "print()\n",
    "\n",
    "train_predictions = classifier.predict(train_sklearn.X)\n",
    "kinecture.report_accuracy(train_predictions, train_sklearn.y, header=\"train\")\n",
    "\n",
    "test09_predictions = classifier.predict(test09_sklearn.X)\n",
    "kinecture.report_accuracy(test09_predictions, test09_sklearn.y, header=\"test09\")\n",
    "\n",
    "test10_predictions = classifier.predict(test10_sklearn.X)\n",
    "kinecture.report_accuracy(test10_predictions, test10_sklearn.y, header=\"test10\")\n",
    "\n",
    "test11_predictions = classifier.predict(test11_sklearn.X)\n",
    "kinecture.report_accuracy(test11_predictions, test11_sklearn.y, header=\"test11\")\n",
    "\n",
    "testall_predictions = classifier.predict(testall_sklearn.X)\n",
    "kinecture.report_accuracy(testall_predictions, testall_sklearn.y, header=\"testall\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
